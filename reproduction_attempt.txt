(.conda) edwin@LAPTOP-5IMR9MI0:~/Projects/operator_learning/powr$ pip install -r requirements.txt
Collecting gymnasium==0.29.1 (from gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)
Collecting imageio==2.34.0 (from -r requirements.txt (line 2))
  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)
Collecting jax==0.4.28 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading jax-0.4.28-py3-none-any.whl.metadata (23 kB)
Collecting matplotlib==3.7.5 (from -r requirements.txt (line 4))
  Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)
Collecting opencv_python==4.9.0.80 (from -r requirements.txt (line 5))
  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)
Collecting tabulate==0.9.0 (from -r requirements.txt (line 6))
  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
Collecting utils==1.0.2 (from -r requirements.txt (line 7))
  Downloading utils-1.0.2.tar.gz (13 kB)
  Preparing metadata (setup.py) ... done
Collecting tensorboardX==2.6.2.2 (from -r requirements.txt (line 8))
  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)
Collecting wandb==0.16.6 (from -r requirements.txt (line 9))
  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)
Collecting tqdm (from -r requirements.txt (line 10))
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting tensorboard (from -r requirements.txt (line 11))
  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)
Collecting rich (from -r requirements.txt (line 12))
  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)
Collecting numpy>=1.21.0 (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Downloading numpy-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
Collecting cloudpickle>=1.2.0 (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)
Collecting typing-extensions>=4.3.0 (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting farama-notifications>=0.0.1 (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)
Collecting pillow>=8.3.2 (from imageio==2.34.0->-r requirements.txt (line 2))
  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)
Collecting ml-dtypes>=0.2.0 (from jax==0.4.28->jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)
Collecting opt-einsum (from jax==0.4.28->jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)
Collecting scipy>=1.9 (from jax==0.4.28->jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)
Collecting contourpy>=1.0.1 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)
Collecting cycler>=0.10 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Downloading fonttools-4.55.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)
Collecting kiwisolver>=1.0.1 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
Collecting numpy>=1.21.0 (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
Collecting packaging>=20.0 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting pyparsing>=2.3.1 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)
Collecting python-dateutil>=2.7 (from matplotlib==3.7.5->-r requirements.txt (line 4))
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting protobuf>=3.20 (from tensorboardX==2.6.2.2->-r requirements.txt (line 8))
  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)
Collecting Click!=8.0.0,>=7.1 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)
Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)
Collecting requests<3,>=2.0.0 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting psutil>=5.0.0 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)
Collecting sentry-sdk>=1.0.0 (from wandb==0.16.6->-r requirements.txt (line 9))
  Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl.metadata (9.9 kB)
Collecting docker-pycreds>=0.4.0 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting PyYAML (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
Collecting setproctitle (from wandb==0.16.6->-r requirements.txt (line 9))
  Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Requirement already satisfied: setuptools in /home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages (from wandb==0.16.6->-r requirements.txt (line 9)) (75.1.0)
Collecting appdirs>=1.4.3 (from wandb==0.16.6->-r requirements.txt (line 9))
  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)
Collecting protobuf>=3.20 (from tensorboardX==2.6.2.2->-r requirements.txt (line 8))
  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)
Collecting pygame>=2.1.3 (from gymnasium[classic-control]==0.29.1->-r requirements.txt (line 1))
  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting jaxlib==0.4.28 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading jaxlib-0.4.28-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting jax-cuda12-plugin==0.4.28 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading jax_cuda12_plugin-0.4.28-cp311-cp311-manylinux2014_x86_64.whl.metadata (560 bytes)
Collecting nvidia-cublas-cu12>=12.1.3.1 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12>=12.1.105 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cuda-nvcc-cu12>=12.1.105 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cuda_nvcc_cu12-12.6.85-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12>=12.1.105 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cudnn-cu12<9.0,>=8.9.2.26 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cufft-cu12>=11.0.2.54 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12>=11.4.5.107 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12>=12.1.0.106 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12>=2.18.1 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Using cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvjitlink-cu12>=12.1.105 (from jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)
Collecting jax-cuda12-pjrt==0.4.28 (from jax-cuda12-plugin==0.4.28->jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading jax_cuda12_pjrt-0.4.28-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)
Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 11))
  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)
Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 11))
  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)
Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 11))
  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)
Collecting six>1.9 (from tensorboard->-r requirements.txt (line 11))
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 11))
  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)
Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 11))
  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)
Collecting markdown-it-py>=2.2.0 (from rich->-r requirements.txt (line 12))
  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich->-r requirements.txt (line 12))
  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)
Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 12))
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Collecting nvidia-cuda-nvrtc-cu12 (from nvidia-cudnn-cu12<9.0,>=8.9.2.26->jax[cuda12]==0.4.28->-r requirements.txt (line 3))
  Downloading nvidia_cuda_nvrtc_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)
Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)
Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)
Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 11))
  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.6->-r requirements.txt (line 9))
  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)
Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 953.9/953.9 kB 16.8 MB/s eta 0:00:00
Downloading imageio-2.34.0-py3-none-any.whl (313 kB)
Downloading jax-0.4.28-py3-none-any.whl (1.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 26.3 MB/s eta 0:00:00
Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.6/11.6 MB 28.3 MB/s eta 0:00:00
Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.2/62.2 MB 51.1 MB/s eta 0:00:00
Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)
Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)
Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 40.9 MB/s eta 0:00:00
Downloading jax_cuda12_plugin-0.4.28-cp311-cp311-manylinux2014_x86_64.whl (12.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 9.5 MB/s eta 0:00:00
Downloading jaxlib-0.4.28-cp311-cp311-manylinux2014_x86_64.whl (77.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.5/77.5 MB 9.5 MB/s eta 0:00:00
Downloading jax_cuda12_pjrt-0.4.28-py3-none-manylinux2014_x86_64.whl (86.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 MB 7.4 MB/s eta 0:00:00
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)
Downloading rich-13.9.4-py3-none-any.whl (242 kB)
Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)
Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)
Using cached click-8.1.7-py3-none-any.whl (97 kB)
Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)
Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)
Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)
Downloading fonttools-4.55.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 48.6 MB/s eta 0:00:00
Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)
Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 57.9 MB/s eta 0:00:00
Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 29.3 MB/s eta 0:00:00
Using cached Markdown-3.7-py3-none-any.whl (106 kB)
Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)
Downloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 53.4 MB/s eta 0:00:00
Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.1/393.1 MB 44.2 MB/s eta 0:00:00
Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 50.8 MB/s eta 0:00:00
Downloading nvidia_cuda_nvcc_cu12-12.6.85-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (21.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.2/21.2 MB 56.8 MB/s eta 0:00:00
Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.7/897.7 kB 32.3 MB/s eta 0:00:00
Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 704.7/704.7 MB 14.0 MB/s eta 0:00:00
Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.2/200.2 MB 42.0 MB/s eta 0:00:00
Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.2/158.2 MB 28.4 MB/s eta 0:00:00
Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.6/216.6 MB 24.8 MB/s eta 0:00:00
Using cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)
Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 41.4 MB/s eta 0:00:00
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 33.5 MB/s eta 0:00:00
Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)
Using cached psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)
Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.0/14.0 MB 58.9 MB/s eta 0:00:00
Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)
Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)
Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)
Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)
Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)
Downloading setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)
Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)
Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)
Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)
Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)
Downloading nvidia_cuda_nvrtc_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (23.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.6/23.6 MB 49.8 MB/s eta 0:00:00
Using cached smmap-5.0.1-py3-none-any.whl (24 kB)
Building wheels for collected packages: utils
  Building wheel for utils (setup.py) ... done
  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=c5dd6c023c06e4affe976dcc626cb165de8b5a72bc6bef1b4c282e4414ff88ed
  Stored in directory: /home/edwin/.cache/pip/wheels/15/0c/b3/674aea8c5d91c642c817d4d630bd58faa316724b136844094d
Successfully built utils
Installing collected packages: jax-cuda12-pjrt, farama-notifications, appdirs, utils, urllib3, typing-extensions, tqdm, tensorboard-data-server, tabulate, smmap, six, setproctitle, PyYAML, pyparsing, pygments, pygame, psutil, protobuf, pillow, packaging, opt-einsum, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, mdurl, MarkupSafe, markdown, kiwisolver, jax-cuda12-plugin, idna, grpcio, fonttools, cycler, cloudpickle, Click, charset-normalizer, certifi, absl-py, werkzeug, tensorboardX, sentry-sdk, scipy, requests, python-dateutil, opencv_python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, ml-dtypes, markdown-it-py, imageio, gymnasium, gitdb, docker-pycreds, contourpy, tensorboard, rich, nvidia-cusolver-cu12, matplotlib, jaxlib, jax, GitPython, wandb
Successfully installed Click-8.1.7 GitPython-3.1.43 MarkupSafe-3.0.2 PyYAML-6.0.2 absl-py-2.1.0 appdirs-1.4.4 certifi-2024.8.30 charset-normalizer-3.4.0 cloudpickle-3.1.0 contourpy-1.3.1 cycler-0.12.1 docker-pycreds-0.4.0 farama-notifications-0.0.4 fonttools-4.55.2 gitdb-4.0.11 grpcio-1.68.1 gymnasium-0.29.1 idna-3.10 imageio-2.34.0 jax-0.4.28 jax-cuda12-pjrt-0.4.28 jax-cuda12-plugin-0.4.28 jaxlib-0.4.28 kiwisolver-1.4.7 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.7.5 mdurl-0.1.2 ml-dtypes-0.5.0 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvcc-cu12-12.6.85 nvidia-cuda-nvrtc-cu12-12.6.85 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.3.0.4 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.23.4 nvidia-nvjitlink-cu12-12.6.85 opencv_python-4.9.0.80 opt-einsum-3.4.0 packaging-24.2 pillow-11.0.0 protobuf-4.25.5 psutil-6.1.0 pygame-2.6.1 pygments-2.18.0 pyparsing-3.2.0 python-dateutil-2.9.0.post0 requests-2.32.3 rich-13.9.4 scipy-1.14.1 sentry-sdk-2.19.2 setproctitle-1.3.4 six-1.17.0 smmap-5.0.1 tabulate-0.9.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.2.3 utils-1.0.2 wandb-0.16.6 werkzeug-3.1.3
(.conda) edwin@LAPTOP-5IMR9MI0:~/Projects/operator_learning/powr$ ls
LICENSE  README.md  docs  misc  powr  requirements.txt  train.py
(.conda) edwin@LAPTOP-5IMR9MI0:~/Projects/operator_learning/powr$ python3 train.py --offline
{'algo': 'powr',
 'checkpoint': None,
 'delete_Q_memory': False,
 'device': 'gpu',
 'early_stopping': None,
 'env': 'MountainCar-v0',
 'epochs': 200,
 'eta': 0.1,
 'eval_episodes': 1,
 'eval_every': 1,
 'gamma': 0.99,
 'group': None,
 'iter_pmd': 1,
 'la': 1e-06,
 'notes': None,
 'offline': True,
 'parallel_envs': 3,
 'project': None,
 'q_mem': 0,
 'save_checkpoint_every': 20,
 'save_gif_every': None,
 'seed': 0,
 'sigma': 0.2,
 'subsamples': 10000,
 'tags': [],
 'train_episodes': 1,
 'warmup_episodes': 1}
Currently running on GPU 
UserWarning: Number of warmup episodes 1 not divisible by parallel environments 3, considering 3 warmup episodes
UserWarning: Number of training episodes 1 not divisible by parallel environments 3, considering 3 training episodes
UserWarning: Number of evaluation episodes 1 not divisible by parallel environments 3, considering 3 evaluation episodes
2024-12-08 21:00:01.114395: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.6.85). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Training the policy
╒═════════════════════╤════════╕
│ Epoch               │      0 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │    600 │
├─────────────────────┼────────┤
│ Sampling time (s)   │ 23.877 │
├─────────────────────┼────────┤
│ Training time (s)   │  1.691 │
├─────────────────────┼────────┤
│ PMD time (s)        │  0.422 │
├─────────────────────┼────────┤
│ Evaluation time (s) │   2.89 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 28.886 │
╘═════════════════════╧════════╛
╒═════════════════════╤═══════╕
│ Epoch               │     1 │
╞═════════════════════╪═══════╡
│ Train reward        │  -200 │
├─────────────────────┼───────┤
│ Eval reward         │  -200 │
├─────────────────────┼───────┤
│ Total timesteps     │  1200 │
├─────────────────────┼───────┤
│ Sampling time (s)   │ 3.706 │
├─────────────────────┼───────┤
│ Training time (s)   │ 1.764 │
├─────────────────────┼───────┤
│ PMD time (s)        │ 0.563 │
├─────────────────────┼───────┤
│ Evaluation time (s) │ 2.618 │
├─────────────────────┼───────┤
│ Execution time (s)  │ 8.667 │
╘═════════════════════╧═══════╛
╒═════════════════════╤════════╕
│ Epoch               │      2 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │   1800 │
├─────────────────────┼────────┤
│ Sampling time (s)   │   4.77 │
├─────────────────────┼────────┤
│ Training time (s)   │  2.349 │
├─────────────────────┼────────┤
│ PMD time (s)        │  0.597 │
├─────────────────────┼────────┤
│ Evaluation time (s) │   2.89 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 10.624 │
╘═════════════════════╧════════╛
╒═════════════════════╤════════╕
│ Epoch               │      3 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │   2400 │
├─────────────────────┼────────┤
│ Sampling time (s)   │  4.912 │
├─────────────────────┼────────┤
│ Training time (s)   │  3.006 │
├─────────────────────┼────────┤
│ PMD time (s)        │  0.861 │
├─────────────────────┼────────┤
│ Evaluation time (s) │  3.671 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 12.467 │
╘═════════════════════╧════════╛
╒═════════════════════╤════════╕
│ Epoch               │      4 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │   3000 │
├─────────────────────┼────────┤
│ Sampling time (s)   │  5.221 │
├─────────────────────┼────────┤
│ Training time (s)   │  3.956 │
├─────────────────────┼────────┤
│ PMD time (s)        │  1.018 │
├─────────────────────┼────────┤
│ Evaluation time (s) │   3.41 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 13.635 │
╘═════════════════════╧════════╛
╒═════════════════════╤════════╕
│ Epoch               │      5 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │   3600 │
├─────────────────────┼────────┤
│ Sampling time (s)   │  5.488 │
├─────────────────────┼────────┤
│ Training time (s)   │  5.243 │
├─────────────────────┼────────┤
│ PMD time (s)        │  1.394 │
├─────────────────────┼────────┤
│ Evaluation time (s) │  3.596 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 15.764 │
╘═════════════════════╧════════╛
╒═════════════════════╤════════╕
│ Epoch               │      6 │
╞═════════════════════╪════════╡
│ Train reward        │   -200 │
├─────────────────────┼────────┤
│ Eval reward         │   -200 │
├─────────────────────┼────────┤
│ Total timesteps     │   4200 │
├─────────────────────┼────────┤
│ Sampling time (s)   │  5.802 │
├─────────────────────┼────────┤
│ Training time (s)   │  7.654 │
├─────────────────────┼────────┤
│ PMD time (s)        │  2.209 │
├─────────────────────┼────────┤
│ Evaluation time (s) │  4.078 │
├─────────────────────┼────────┤
│ Execution time (s)  │ 19.801 │
╘═════════════════════╧════════╛
╒═════════════════════╤══════════╕
│ Epoch               │        7 │
╞═════════════════════╪══════════╡
│ Train reward        │     -189 │
├─────────────────────┼──────────┤
│ Eval reward         │ -197.667 │
├─────────────────────┼──────────┤
│ Total timesteps     │     4767 │
├─────────────────────┼──────────┤
│ Sampling time (s)   │   10.483 │
├─────────────────────┼──────────┤
│ Training time (s)   │   10.168 │
├─────────────────────┼──────────┤
│ PMD time (s)        │    2.438 │
├─────────────────────┼──────────┤
│ Evaluation time (s) │    4.523 │
├─────────────────────┼──────────┤
│ Execution time (s)  │   27.689 │
╘═════════════════════╧══════════╛
╒═════════════════════╤══════════╕
│ Epoch               │        8 │
╞═════════════════════╪══════════╡
│ Train reward        │     -179 │
├─────────────────────┼──────────┤
│ Eval reward         │ -189.667 │
├─────────────────────┼──────────┤
│ Total timesteps     │     5304 │
├─────────────────────┼──────────┤
│ Sampling time (s)   │   12.986 │
├─────────────────────┼──────────┤
│ Training time (s)   │   13.555 │
├─────────────────────┼──────────┤
│ PMD time (s)        │    3.094 │
├─────────────────────┼──────────┤
│ Evaluation time (s) │    4.884 │
├─────────────────────┼──────────┤
│ Execution time (s)  │   34.613 │
╘═════════════════════╧══════════╛
╒═════════════════════╤══════════╕
│ Epoch               │        9 │
╞═════════════════════╪══════════╡
│ Train reward        │ -167.333 │
├─────────────────────┼──────────┤
│ Eval reward         │     -194 │
├─────────────────────┼──────────┤
│ Total timesteps     │     5806 │
├─────────────────────┼──────────┤
│ Sampling time (s)   │    8.519 │
├─────────────────────┼──────────┤
│ Training time (s)   │   15.921 │
├─────────────────────┼──────────┤
│ PMD time (s)        │    3.626 │
├─────────────────────┼──────────┤
│ Evaluation time (s) │    3.997 │
├─────────────────────┼──────────┤
│ Execution time (s)  │   32.177 │
╘═════════════════════╧══════════╛
╒═════════════════════╤══════════╕
│ Epoch               │       10 │
╞═════════════════════╪══════════╡
│ Train reward        │ -173.667 │
├─────────────────────┼──────────┤
│ Eval reward         │ -171.333 │
├─────────────────────┼──────────┤
│ Total timesteps     │     6327 │
├─────────────────────┼──────────┤
│ Sampling time (s)   │    7.536 │
├─────────────────────┼──────────┤
│ Training time (s)   │   19.676 │
├─────────────────────┼──────────┤
│ PMD time (s)        │    4.454 │
├─────────────────────┼──────────┤
│ Evaluation time (s) │    5.435 │
├─────────────────────┼──────────┤
│ Execution time (s)  │   37.231 │
╘═════════════════════╧══════════╛
   6% ━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11/200  [ 0:03:55 < -:--:-- , ? it/s ]2024-12-08 21:04:21.325410: W external/tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB (rounded to 1870970368)requested by op 
2024-12-08 21:04:21.325569: W external/tsl/tsl/framework/bfc_allocator.cc:494] **********____****************________*************************_____________________________________
E1208 21:04:21.325641    4506 pjrt_stream_executor_client.cc:2826] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1870970272 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:  355.49MiB
              constant allocation:         0B
        maybe_live_out allocation:  355.54MiB
     preallocated temp allocation:    1.74GiB
                 total allocation:    2.44GiB
              total fragmentation:       148B (0.00%)
Peak buffers:
        Buffer 1:
                Size: 1.39GiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: custom-call
                Shape: f64[187276987]
                ==========================

        Buffer 2:
                Size: 355.49MiB
                XLA Label: fusion
                Shape: f64[6826,6826]
                ==========================

        Buffer 3:
                Size: 355.49MiB
                Entry Parameter Subshape: f64[6826,6826]
                ==========================

        Buffer 4:
                Size: 355.49MiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: fusion
                Shape: f64[6826,6826]
                ==========================

        Buffer 5:
                Size: 53.3KiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: fusion
                Shape: f64[6826]
                ==========================

        Buffer 6:
                Size: 32B
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: custom-call
                Shape: (f64[6826,6826], f64[6826], s32[], f64[187276987])
                ==========================

        Buffer 7:
                Size: 16B
                XLA Label: tuple
                Shape: (f64[6826,6826], f64[6826])
                ==========================


   6% ━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11/200  [ 0:03:55 < -:--:-- , ? it/s ]
Traceback (most recent call last):
  File "/home/edwin/Projects/operator_learning/powr/train.py", line 339, in <module>
    powr.train( 
    ^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/powr/powr/powr.py", line 154, in train
    self.mdp_manager.train()
  File "/home/edwin/Projects/operator_learning/powr/powr/MDPManager.py", line 390, in train
    self.FTL.train()
  File "/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py", line 138, in train
    V, W = jax.lax.linalg.eigh(self.K_sub_sub)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/lax/linalg.py", line 162, in eigh
    v, w = eigh_p.bind(
           ^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/core.py", line 387, in bind
    return self.bind_with_trace(find_top_trace(args), args, params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/core.py", line 391, in bind_with_trace
    out = trace.process_primitive(self, map(trace.full_raise, args), params)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/core.py", line 879, in process_primitive
    return primitive.impl(*tracers, **params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/lax/linalg.py", line 665, in _eigh_impl
    v, w = dispatch.apply_primitive(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/edwin/Projects/operator_learning/.conda/lib/python3.11/site-packages/jax/_src/dispatch.py", line 86, in apply_primitive
    outs = fun(*args)
           ^^^^^^^^^^
jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1870970272 bytes.
BufferAssignment OOM Debugging.
BufferAssignment stats:
             parameter allocation:  355.49MiB
              constant allocation:         0B
        maybe_live_out allocation:  355.54MiB
     preallocated temp allocation:    1.74GiB
                 total allocation:    2.44GiB
              total fragmentation:       148B (0.00%)
Peak buffers:
        Buffer 1:
                Size: 1.39GiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: custom-call
                Shape: f64[187276987]
                ==========================

        Buffer 2:
                Size: 355.49MiB
                XLA Label: fusion
                Shape: f64[6826,6826]
                ==========================

        Buffer 3:
                Size: 355.49MiB
                Entry Parameter Subshape: f64[6826,6826]
                ==========================

        Buffer 4:
                Size: 355.49MiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: fusion
                Shape: f64[6826,6826]
                ==========================

        Buffer 5:
                Size: 53.3KiB
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: fusion
                Shape: f64[6826]
                ==========================

        Buffer 6:
                Size: 32B
                Operator: op_name="jit(eigh)/jit(main)/eigh[lower=True sort_eigenvalues=True subset_by_index=None]" source_file="/home/edwin/Projects/operator_learning/powr/powr/IncrementalRLS.py" source_line=138
                XLA Label: custom-call
                Shape: (f64[6826,6826], f64[6826], s32[], f64[187276987])
                ==========================

        Buffer 7:
                Size: 16B
                XLA Label: tuple
                Shape: (f64[6826,6826], f64[6826])
                ==========================


--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.