{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import wandb\n",
    "import socket\n",
    "import logging\n",
    "import warnings\n",
    "import argparse\n",
    "import gymnasium as gym\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import TqdmExperimentalWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=TqdmExperimentalWarning\n",
    ")  # Remove experimental warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from powr.utils import *\n",
    "from powr.wrappers import *\n",
    "from powr.powr import POWR\n",
    "from powr.kernels import dirac_kernel, gaussian_kernel, gaussian_kernel_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARNING)\n",
    "logging.getLogger('jax').setLevel(logging.WARNING)\n",
    "logging.getLogger('tensorboardX').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    env=\"MountainCar-v0\",\n",
    "    group=None,\n",
    "    project=None,\n",
    "    la=1e-6,\n",
    "    eta=0.1,\n",
    "    gamma=0.99,\n",
    "    sigma=0.2,\n",
    "    q_mem=0,\n",
    "    delete_Q_memory=False,\n",
    "    early_stopping=None,\n",
    "    warmup_episodes=1,\n",
    "    epochs=8,\n",
    "    train_episodes=1,\n",
    "    parallel_envs=3,\n",
    "    subsamples=1_000,\n",
    "    iter_pmd=1,\n",
    "    eval_episodes=1,\n",
    "    save_gif_every=None,\n",
    "    save_checkpoint_every=20,\n",
    "    eval_every=1,\n",
    "    seed=0,\n",
    "    checkpoint=None,\n",
    "    device=\"gpu\",\n",
    "    notes=None,\n",
    "    tags=[],\n",
    "    offline=True,\n",
    ")\n",
    "args.algo = \"powr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo': 'powr',\n",
      " 'checkpoint': None,\n",
      " 'delete_Q_memory': False,\n",
      " 'device': 'gpu',\n",
      " 'early_stopping': None,\n",
      " 'env': 'MountainCar-v0',\n",
      " 'epochs': 8,\n",
      " 'eta': 0.1,\n",
      " 'eval_episodes': 1,\n",
      " 'eval_every': 1,\n",
      " 'gamma': 0.99,\n",
      " 'group': None,\n",
      " 'iter_pmd': 1,\n",
      " 'la': 1e-06,\n",
      " 'notes': None,\n",
      " 'offline': True,\n",
      " 'parallel_envs': 3,\n",
      " 'project': None,\n",
      " 'q_mem': 0,\n",
      " 'save_checkpoint_every': 20,\n",
      " 'save_gif_every': None,\n",
      " 'seed': 0,\n",
      " 'sigma': 0.2,\n",
      " 'subsamples': 1000,\n",
      " 'tags': [],\n",
      " 'train_episodes': 1,\n",
      " 'warmup_episodes': 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'total_timesteps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     29\u001b[0m random_string \u001b[38;5;241m=\u001b[39m get_random_string(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     30\u001b[0m current_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m run_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39malgo\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[43mget_run_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;241m+\u001b[39m random_string\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m create_dirs(run_path)\n\u001b[1;32m     43\u001b[0m save_config(\u001b[38;5;28mvars\u001b[39m(args), run_path)\n",
      "File \u001b[0;32m~/Projects/operator_learning/powr/powr/utils.py:60\u001b[0m, in \u001b[0;36mget_run_name\u001b[0;34m(args, current_date)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     current_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mstr\u001b[39m(current_date)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39menv)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39malgo)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_t\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_HiddenL\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39mhidden_layers)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_activation-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mactivation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_seed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(args\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m+\u001b[39m socket\u001b[38;5;241m.\u001b[39mgethostname()\n\u001b[1;32m     68\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'total_timesteps'"
     ]
    }
   ],
   "source": [
    "# ** Wandb Settings **\n",
    "# Resume Wandb run if checkpoint is provided\n",
    "\n",
    "checkpoint = args.checkpoint\n",
    "if checkpoint is not None:\n",
    "    checkpoint_data = load_checkpoint(checkpoint)\n",
    "    project = args.project\n",
    "\n",
    "    # Load saved `args`, `total_timesteps`, and `wandb_run_id`\n",
    "    args = argparse.Namespace(**checkpoint_data[\"args\"])\n",
    "    total_timesteps = checkpoint_data[\"total_timesteps\"]\n",
    "    starting_epoch = checkpoint_data[\"epoch\"]\n",
    "    wandb_run_id = checkpoint_data[\"wandb_run_id\"]\n",
    "    print(\"Resuming WandB run: \", wandb_run_id)\n",
    "    # Resume Wandb run with saved run ID\n",
    "    wandb.init(\n",
    "        project=project,\n",
    "        id=wandb_run_id,  # Use saved Wandb run ID to resume the run\n",
    "        save_code=True,\n",
    "        sync_tensorboard=True,\n",
    "        monitor_gym=True,\n",
    "        resume=\"must\",\n",
    "        mode=(\"online\" if not args.offline else \"disabled\"),\n",
    "    )\n",
    "\n",
    "    run_path = f\"{checkpoint}/\"\n",
    "else:\n",
    "    pprint(vars(args))\n",
    "    random_string = get_random_string(5)\n",
    "    current_date = datetime.today().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    run_path = (\n",
    "        \"runs/\"\n",
    "        + str(args.env)\n",
    "        + \"/\"\n",
    "        + args.algo\n",
    "        + \"/\"\n",
    "        + get_run_name(args, current_date)\n",
    "        + \"_\"\n",
    "        + random_string\n",
    "        + \"/\"\n",
    "    )\n",
    "    create_dirs(run_path)\n",
    "    save_config(vars(args), run_path)\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        config=vars(args),\n",
    "        project=(\"powr\" if args.project is None else args.project),\n",
    "        group=(f\"{args.env}/{args.algo}\" if args.group is None else args.group),\n",
    "        name=str(current_date)\n",
    "        + \"_\"\n",
    "        + str(args.env)\n",
    "        + \"_\"\n",
    "        + args.algo\n",
    "        + \"_eta=\"\n",
    "        + str(args.eta)\n",
    "        + \"_la=\"\n",
    "        + str(args.la)\n",
    "        + \"_train_eps=\"\n",
    "        + str(args.train_episodes)\n",
    "        + \"_pmd_iters=\"\n",
    "        + str(args.iter_pmd)\n",
    "        + \"_earlystop=\"\n",
    "        + str(args.early_stopping)\n",
    "        + \"_seed\"\n",
    "        + str(args.seed)\n",
    "        + \"_\"\n",
    "        + random_string,\n",
    "        save_code=True,\n",
    "        sync_tensorboard=True,\n",
    "        tags=args.tags,\n",
    "        monitor_gym=True,\n",
    "        notes=args.notes,\n",
    "        mode=(\"online\" if not args.offline else \"disabled\"),\n",
    "    )\n",
    "    starting_epoch = 0\n",
    "    total_timesteps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--env ENV] [--group GROUP]\n",
      "                             [--project PROJECT] [--la LA] [--eta ETA]\n",
      "                             [--gamma GAMMA] [--sigma SIGMA] [--q-mem Q_MEM]\n",
      "                             [--delete-Q-memory]\n",
      "                             [--early-stopping EARLY_STOPPING]\n",
      "                             [--warmup-episodes WARMUP_EPISODES]\n",
      "                             [--epochs EPOCHS]\n",
      "                             [--train-episodes TRAIN_EPISODES]\n",
      "                             [--parallel-envs PARALLEL_ENVS]\n",
      "                             [--subsamples SUBSAMPLES] [--iter-pmd ITER_PMD]\n",
      "                             [--eval-episodes EVAL_EPISODES]\n",
      "                             [--save-gif-every SAVE_GIF_EVERY]\n",
      "                             [--save-checkpoint-every SAVE_CHECKPOINT_EVERY]\n",
      "                             [--eval-every EVAL_EVERY] [--seed SEED]\n",
      "                             [--checkpoint CHECKPOINT] [--device DEVICE]\n",
      "                             [--notes NOTES] [--tags TAGS [TAGS ...]]\n",
      "                             [--offline]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/edwin/.local/share/jupyter/runtime/kernel-v325a341c820740b0e721f2cab173263fd67cb62c2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# ** Device Settings **\n",
    "device_setting = args.device\n",
    "if device_setting == \"gpu\":\n",
    "    device = jax.devices(\"gpu\")[0]\n",
    "    jax.config.update(\"jax_default_device\", device)  # Update the default device to GPU\n",
    "\n",
    "    print(f\"Currently running on \\033[92mGPU {RESET}\")\n",
    "elif device_setting == \"cpu\":\n",
    "    \n",
    "    try:\n",
    "        os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "        device = jax.devices(\"cpu\")[0]  \n",
    "        jax.config.update(\"jax_default_device\", device)  # Update the default device to CPU\n",
    "    except:\n",
    "        os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "        jax.config.update(\"jax_default_device\", jax.devices(\"cpu\")[0])\n",
    "\n",
    "    print(f\"Currently running on \\033[92mCPU {RESET}\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown device setting {device_setting}, please use <cpu> or <gpu>\")\n",
    "\n",
    "\n",
    "# ** Logging Settings **\n",
    "# Create tensorboard writer\n",
    "writer = SummaryWriter(f\"{run_path}\")\n",
    "writer.add_text(\n",
    "    \"hyperparameters\",\n",
    "    \"|param|value|\\n|-|-|\\n%s\"\n",
    "    % (\"\\n\".join([f\"|{key}|{value}|\" for key, value in vars(args).items()])),\n",
    ")\n",
    "\n",
    "# Create log file\n",
    "log_file = open(os.path.join((run_path), \"log_file.txt\"), \"a\", encoding=\"utf-8\")\n",
    "\n",
    "# ** Hyperparameters Settings **\n",
    "subsamples = args.subsamples\n",
    "la = args.la\n",
    "eta = args.eta\n",
    "gamma = args.gamma\n",
    "q_memories = args.q_mem\n",
    "\n",
    "parallel_envs = args.parallel_envs\n",
    "warmup_episodes = args.warmup_episodes\n",
    "assert warmup_episodes > 0, \"Number of warmup episodes must be greater than 0\"\n",
    "if warmup_episodes % parallel_envs != 0:\n",
    "\n",
    "    warnings.warn(\n",
    "            f\"Number of warmup episodes {warmup_episodes} not divisible by parallel environments {parallel_envs}, considering {(warmup_episodes // parallel_envs + 1)*parallel_envs} warmup episodes\",\n",
    "            UserWarning,\n",
    "        )        \n",
    "    warmup_episodes = warmup_episodes//parallel_envs + 1\n",
    "else:\n",
    "    warmup_episodes = warmup_episodes//parallel_envs\n",
    "\n",
    "epochs = args.epochs\n",
    "train_episodes = args.train_episodes\n",
    "if train_episodes % parallel_envs != 0:\n",
    "\n",
    "    warnings.warn(\n",
    "            f\"Number of training episodes {train_episodes} not divisible by parallel environments {parallel_envs}, considering {(train_episodes // parallel_envs + 1)*parallel_envs} training episodes\",\n",
    "            UserWarning,\n",
    "        )        \n",
    "    train_episodes = train_episodes//parallel_envs + 1\n",
    "else:\n",
    "    train_episodes = train_episodes//parallel_envs\n",
    "\n",
    "iter_pmd = args.iter_pmd\n",
    "eval_episodes = args.eval_episodes\n",
    "if eval_episodes % parallel_envs != 0:\n",
    "\n",
    "    warnings.warn(\n",
    "            f\"Number of evaluation episodes {eval_episodes} not divisible by parallel environments {parallel_envs}, considering {(eval_episodes // parallel_envs + 1)*parallel_envs} evaluation episodes\",\n",
    "            UserWarning,\n",
    "        )        \n",
    "    eval_episodes = eval_episodes//parallel_envs + 1\n",
    "else:\n",
    "    eval_episodes = eval_episodes//parallel_envs\n",
    "\n",
    "assert args.early_stopping is None or args.early_stopping > 0, \"Number of early stopping episodes must be greater than 0\"\n",
    "early_stopping = args.early_stopping/parallel_envs if args.early_stopping is not None else None\n",
    "\n",
    "save_gif_every = args.save_gif_every\n",
    "eval_every = args.eval_every\n",
    "save_checkpoint_every = args.save_checkpoint_every  \n",
    "delete_Q_memory = args.delete_Q_memory\n",
    "\n",
    "# ** Environment Settings **\n",
    "env, kernel = parse_env(args.env, parallel_envs, args.sigma)\n",
    "\n",
    "# ** Kernel Settings **\n",
    "def to_be_jit_kernel(X, Y):\n",
    "    return kernel(X, Y)\n",
    "\n",
    "jit_kernel = jax.jit(to_be_jit_kernel)\n",
    "v_jit_kernel = jax.vmap(jit_kernel) # TODO Not used\n",
    "\n",
    "# ** Seed Settings**\n",
    "set_seed(args.seed)\n",
    "\n",
    "# ** POWR Initialization **\n",
    "powr = POWR(\n",
    "        env, \n",
    "        env, \n",
    "        args,\n",
    "        eta=eta, \n",
    "        la=la, \n",
    "        gamma=gamma, \n",
    "        kernel=jit_kernel,\n",
    "        subsamples=subsamples,\n",
    "        q_memories=q_memories,\n",
    "        delete_Q_memory=delete_Q_memory,\n",
    "        early_stopping=early_stopping,\n",
    "        tensorboard_writer=writer,\n",
    "        starting_logging_epoch=starting_epoch,\n",
    "        starting_logging_timestep=total_timesteps,\n",
    "        run_path=run_path,\n",
    "        seed=args.seed,\n",
    "        checkpoint=checkpoint,\n",
    "        device=device_setting,\n",
    "        offline=args.offline,\n",
    "    \n",
    ")\n",
    "\n",
    "# ** Training **\n",
    "print(f\"\\033[1m\\033[94mTraining the policy{RESET}\")\n",
    "powr.train( \n",
    "    epochs=epochs,\n",
    "    warmup_episodes = warmup_episodes,\n",
    "    train_episodes = train_episodes,\n",
    "    eval_episodes = eval_episodes,\n",
    "    iterations_pmd= iter_pmd,\n",
    "    eval_every=eval_every,\n",
    "    save_gif_every=save_gif_every,\n",
    "    save_checkpoint_every=save_checkpoint_every,\n",
    "    args_to_save=args,\n",
    ") \n",
    "\n",
    "# ** Testing **\n",
    "print(f\"\\033[1m\\033[94mTesting the policy{RESET}\")\n",
    "n_test_episodes = 10\n",
    "mean_reward = powr.evaluate(n_test_episodes)\n",
    "\n",
    "print(f\"Policy mean reward over {n_test_episodes} episodes: {mean_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
